# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BDW5b4XJLbquboTZs6Z-_GkiL97aXgnC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

def load_mnist_from_csv(train_path, test_path):
    train_data = pd.read_csv(train_path)

    if train_data.isna().any().any():
        print(f"Found {train_data.isna().sum().sum()} NaN values in training data")
        train_data = train_data.fillna(0)

    X_train = train_data.iloc[:, 1:].values / 255.0
    y_train = train_data.iloc[:, 0].values

    test_data = pd.read_csv(test_path)

    if test_data.isna().any().any():
        print(f"Found {test_data.isna().sum().sum()} NaN values in test data")
        test_data = test_data.fillna(0)

    X_test = test_data.iloc[:, 1:].values / 255.0
    y_test = test_data.iloc[:, 0].values

    return X_train, y_train, X_test, y_test

def visualize_digits(X, y, num_samples=5):
    plt.figure(figsize=(15, 3))
    for i in range(num_samples):
        plt.subplot(1, num_samples, i+1)
        plt.imshow(X[i].reshape(28, 28), cmap='gray')
        plt.title(f"Label: {y[i]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()

def train_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=5):

    knn = KNeighborsClassifier(n_neighbors=n_neighbors)

    start_time = time.time()

    knn.fit(X_train, y_train)

    train_time = time.time() - start_time

    start_time = time.time()

    y_pred = knn.predict(X_test)

    predict_time = time.time() - start_time

    accuracy = accuracy_score(y_test, y_pred)

    print(f"Model training time: {train_time:.2f} seconds")
    print(f"Prediction time: {predict_time:.2f} seconds")
    print(f"Accuracy: {accuracy:.4f}")

    return knn, y_pred

def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()

def find_optimal_k(X_train, y_train, X_val, y_val, k_range):
    if np.isnan(X_train).any() or np.isnan(X_val).any():
        print("Warning: Input data contains NaN values. Replacing with zeros...")
        X_train = np.nan_to_num(X_train)
        X_val = np.nan_to_num(X_val)

    accuracies = []

    for k in k_range:
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(X_train, y_train)
        y_pred = knn.predict(X_val)
        accuracies.append(accuracy_score(y_val, y_pred))
        print(f"K = {k}, Accuracy = {accuracies[-1]:.4f}")

    plt.figure(figsize=(10, 6))
    plt.plot(k_range, accuracies, 'o-')
    plt.xlabel('Number of Neighbors (K)')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs. K Value')
    plt.grid(True)
    plt.show()

    optimal_k = k_range[np.argmax(accuracies)]
    print(f"\nOptimal K value: {optimal_k}")

    return optimal_k

if __name__ == "__main__":
    train_path = "/content/sample_data/mnist_train.csv"
    test_path = "/content/sample_data/mnist_test.csv"

    X_train, y_train, X_test, y_test = load_mnist_from_csv(train_path, test_path)

    if np.isnan(X_train).any() or np.isnan(X_test).any():
        print("Warning: Data still contains NaN values after loading. Replacing with zeros...")
        X_train = np.nan_to_num(X_train)
        X_test = np.nan_to_num(X_test)

    print(f"Training data shape: {X_train.shape}")
    print(f"Test data shape: {X_test.shape}")

    print("Displaying sample digits: ")
    visualize_digits(X_train, y_train)

    X_train_subset, X_val, y_train_subset, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42)

    subset_size = min(5000, len(X_train_subset))
    k_range = [1, 3, 5, 7, 9]
    print(f"Finding optimal K using {subset_size} samples")
    optimal_k = find_optimal_k(
        X_train_subset[:subset_size],
        y_train_subset[:subset_size],
        X_val[:1000],
        y_val[:1000],
        k_range
    )

    print("Training final KNN model:")
    knn, y_pred = train_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=optimal_k)

    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    print("Plotting confusion matrix:")
    plot_confusion_matrix(y_test, y_pred)

    print("Displaying some test predictions:")
    indices = np.random.randint(0, len(X_test), 5)
    X_samples = X_test[indices]
    y_true = y_test[indices]
    y_predicted = knn.predict(X_samples)

    plt.figure(figsize=(15, 3))
    for i in range(5):
        plt.subplot(1, 5, i+1)
        plt.imshow(X_samples[i].reshape(28, 28), cmap='gray')
        plt.title(f"True: {y_true[i]}\nPred: {y_predicted[i]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    train_path = "/content/sample_data/mnist_train.csv"
    test_path = "/content/sample_data/mnist_test.csv"

    X_train, y_train, X_test, y_test = load_mnist_from_csv(train_path, test_path)

    if np.isnan(X_train).any() or np.isnan(X_test).any():
        print("Warning: Data still contains NaN values after loading. Replacing with zeros...")
        X_train = np.nan_to_num(X_train)
        X_test = np.nan_to_num(X_test)

    print(f"Training data shape: {X_train.shape}")
    print(f"Test data shape: {X_test.shape}")

    print("Displaying sample digits: ")
    visualize_digits(X_train, y_train)

    X_train_subset, X_val, y_train_subset, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42)

    subset_size = min(5000, len(X_train_subset))

    def train_evaluate_rfc(X_train, y_train, X_test, y_test):
      clf = RandomForestClassifier(n_estimators=100)

      start_time = time.time()

      clf.fit(X_train, y_train)

      train_time = time.time() - start_time

      start_time = time.time()

      y_pred = clf.predict(X_test)

      predict_time = time.time() - start_time

      accuracy = accuracy_score(y_test, y_pred)

      print(f"Model training time: {train_time:.2f} seconds")
      print(f"Prediction time: {predict_time:.2f} seconds")
      print(f"Accuracy: {accuracy:.4f}")

      return clf, y_pred

    print("Training final RFC model:")
    clf, y_pred = train_evaluate_knn(X_train, y_train, X_test, y_test)

    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    print("Plotting confusion matrix:")
    plot_confusion_matrix(y_test, y_pred)

    print("Displaying some test predictions:")
    indices = np.random.randint(0, len(X_test), 5)
    X_samples = X_test[indices]
    y_true = y_test[indices]
    y_predicted = knn.predict(X_samples)

    plt.figure(figsize=(15, 3))
    for i in range(5):
        plt.subplot(1, 5, i+1)
        plt.imshow(X_samples[i].reshape(28, 28), cmap='gray')
        plt.title(f"True: {y_true[i]}\nPred: {y_predicted[i]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()

